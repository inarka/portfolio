{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Знакомство-с-данными\" data-toc-modified-id=\"Знакомство-с-данными-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Знакомство с данными</a></span></li><li><span><a href=\"#Предобработка-данных\" data-toc-modified-id=\"Предобработка-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Предобработка данных</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение токсичных комментариев для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "rs=1923"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знакомство с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем файл с данными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам дан датасет, в котором 159292 записей. Один из столбцов, Unnamed: 0, не несет в себе полезной информации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153484</th>\n",
       "      <td>153641</td>\n",
       "      <td>The British resistance was broken and the sett...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>7013</td>\n",
       "      <td>Who exactly did she apologise to?  The Comment...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68208</th>\n",
       "      <td>68276</td>\n",
       "      <td>{{unblock|Then you should also block Libro0 si...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56606</th>\n",
       "      <td>56667</td>\n",
       "      <td>hi \\n\\nyou are a fucking bitch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140586</th>\n",
       "      <td>140738</td>\n",
       "      <td>That's what you're heavily implying in linking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "153484      153641  The British resistance was broken and the sett...      0\n",
       "7005          7013  Who exactly did she apologise to?  The Comment...      0\n",
       "68208        68276  {{unblock|Then you should also block Libro0 si...      0\n",
       "56606        56667                     hi \\n\\nyou are a fucking bitch      1\n",
       "140586      140738  That's what you're heavily implying in linking...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как распределены классы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных присутствует дисбаланс классов, положительный класс составляет всего 10% данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала с помощью регулярных выражений очистим текст от нерелевантных символов, таких как знаки препинания, спец. символы и тд. Оставим только символы английского алфавита. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return ' '.join(text.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_processed'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46656</th>\n",
       "      <td>46711</td>\n",
       "      <td>\"\\n\\n LAN A340 solely for Sydney? \\n\\nThis art...</td>\n",
       "      <td>0</td>\n",
       "      <td>lan a solely for sydney this article says that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93856</th>\n",
       "      <td>93948</td>\n",
       "      <td>1248277865155 define recognition]? Lately it's...</td>\n",
       "      <td>0</td>\n",
       "      <td>define recognition lately it s been kind of wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142326</th>\n",
       "      <td>142479</td>\n",
       "      <td>\"\\n\\n Sodomy \\n\\nHave you thought about creati...</td>\n",
       "      <td>1</td>\n",
       "      <td>sodomy have you thought about creating a wikip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146322</th>\n",
       "      <td>146478</td>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
       "      <td>0</td>\n",
       "      <td>please do not vandalize pages as you did with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129925</th>\n",
       "      <td>130061</td>\n",
       "      <td>Fixed Up article\\nI Just fixed up her discogra...</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed up article i just fixed up her discograp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic  \\\n",
       "46656        46711  \"\\n\\n LAN A340 solely for Sydney? \\n\\nThis art...      0   \n",
       "93856        93948  1248277865155 define recognition]? Lately it's...      0   \n",
       "142326      142479  \"\\n\\n Sodomy \\n\\nHave you thought about creati...      1   \n",
       "146322      146478  \"\\n\\n Please do not vandalize pages, as you di...      0   \n",
       "129925      130061  Fixed Up article\\nI Just fixed up her discogra...      0   \n",
       "\n",
       "                                           text_processed  \n",
       "46656   lan a solely for sydney this article says that...  \n",
       "93856   define recognition lately it s been kind of wa...  \n",
       "142326  sodomy have you thought about creating a wikip...  \n",
       "146322  please do not vandalize pages as you did with ...  \n",
       "129925  fixed up article i just fixed up her discograp...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь удалим стоп-слова (слова, не несущие смысла). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    return \" \".join([word for word in text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_processed'] = data['text_processed'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87791</th>\n",
       "      <td>87872</td>\n",
       "      <td>I thought about this some more and went ahead ...</td>\n",
       "      <td>0</td>\n",
       "      <td>thought went ahead emailed talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66957</th>\n",
       "      <td>67024</td>\n",
       "      <td>a gentle warning \\n\\nBy now it should be evide...</td>\n",
       "      <td>0</td>\n",
       "      <td>gentle warning evident many editors watching b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122217</th>\n",
       "      <td>122322</td>\n",
       "      <td>\"\\n\\n\"\"Nice try\"\"? What a silly statement. I h...</td>\n",
       "      <td>0</td>\n",
       "      <td>nice try silly statement violated policies nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38096</th>\n",
       "      <td>38142</td>\n",
       "      <td>It's true too. See the top of my talk page -_-...</td>\n",
       "      <td>0</td>\n",
       "      <td>true see top talk page user talk mistress seli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43766</th>\n",
       "      <td>43819</td>\n",
       "      <td>President Jackson in 1760 ???? -please check y...</td>\n",
       "      <td>0</td>\n",
       "      <td>president jackson please check history</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic  \\\n",
       "87791        87872  I thought about this some more and went ahead ...      0   \n",
       "66957        67024  a gentle warning \\n\\nBy now it should be evide...      0   \n",
       "122217      122322  \"\\n\\n\"\"Nice try\"\"? What a silly statement. I h...      0   \n",
       "38096        38142  It's true too. See the top of my talk page -_-...      0   \n",
       "43766        43819  President Jackson in 1760 ???? -please check y...      0   \n",
       "\n",
       "                                           text_processed  \n",
       "87791                     thought went ahead emailed talk  \n",
       "66957   gentle warning evident many editors watching b...  \n",
       "122217  nice try silly statement violated policies nea...  \n",
       "38096   true see top talk page user talk mistress seli...  \n",
       "43766              president jackson please check history  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем тексты. Обработку будем проводить с помощью библиотеки `spiCy`, в которой лемматизация и POS-теггинг интегрированы в стандартный пайплайн обработки текста, то есть при ее использовании не нужно явно указывать части речи для корректной лемматизации. Также для эффективной обработки применим `nlp.pipe`, который обрабатывает тексты пакетами и позволяет \"отключать\" ненужные компоненты пайплайна. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_lemmatize_pipe(texts):\n",
    "    lemmas_texts = []\n",
    "    for doc in tqdm(nlp.pipe(texts, disable=[\"parser\", \"ner\"]), total=len(texts)):\n",
    "        lemmas_texts.append(' '.join([token.lemma_ for token in doc]))\n",
    "    return lemmas_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 159292/159292 [04:03<00:00, 654.11it/s]\n"
     ]
    }
   ],
   "source": [
    "data['text_processed'] = spacy_lemmatize_pipe(data['text_processed'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25888</th>\n",
       "      <td>25912</td>\n",
       "      <td>Blocked\\nIt would appear from your edit histor...</td>\n",
       "      <td>0</td>\n",
       "      <td>block would appear edit history use sort autom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100625</th>\n",
       "      <td>100722</td>\n",
       "      <td>Your comments on Ireland (state) talk (whateve...</td>\n",
       "      <td>1</td>\n",
       "      <td>comment ireland state talk whatever call frank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92799</th>\n",
       "      <td>92891</td>\n",
       "      <td>I am coming to get you \\n\\ni know where you li...</td>\n",
       "      <td>1</td>\n",
       "      <td>come get know live I m go come rape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147575</th>\n",
       "      <td>147731</td>\n",
       "      <td>On account of the project deciding to ignore h...</td>\n",
       "      <td>1</td>\n",
       "      <td>account project decide ignore history hereby q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>6438</td>\n",
       "      <td>Would we still be able to receive the previous...</td>\n",
       "      <td>0</td>\n",
       "      <td>would still able receive previous article write</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic  \\\n",
       "25888        25912  Blocked\\nIt would appear from your edit histor...      0   \n",
       "100625      100722  Your comments on Ireland (state) talk (whateve...      1   \n",
       "92799        92891  I am coming to get you \\n\\ni know where you li...      1   \n",
       "147575      147731  On account of the project deciding to ignore h...      1   \n",
       "6434          6438  Would we still be able to receive the previous...      0   \n",
       "\n",
       "                                           text_processed  \n",
       "25888   block would appear edit history use sort autom...  \n",
       "100625  comment ireland state talk whatever call frank...  \n",
       "92799                 come get know live I m go come rape  \n",
       "147575  account project decide ignore history hereby q...  \n",
       "6434      would still able receive previous article write  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим в данных только информативные столбцы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text_processed', 'toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man really try edit war guy constantly rem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make real suggestion improvement wonder sectio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  toxic\n",
       "0  explanation edit make username hardcore metall...      0\n",
       "1  aww match background colour seemingly stuck th...      0\n",
       "2  hey man really try edit war guy constantly rem...      0\n",
       "3  make real suggestion improvement wonder sectio...      0\n",
       "4                      sir hero chance remember page      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.25, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся счетчиком величин TF-IDF из sklearn, создадим объект, который затем будем использовать внутри  `Pipeline`. Это необходимо, чтобы на кросс-валидации не происходило утечки данных из валидационной выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "\n",
    "features_train = train['text_processed']\n",
    "target_train = train['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На следующем этапе с помощью кросс-валидации обучим модели Логистической регрессии, Случайного леса и LightGBM. Для всех трех моделей укажем, что выборка несбалансирована. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры лучшей модели логистической регрессии : {'lr__C': 11, 'lr__solver': 'liblinear'}\n",
      "F1 для лучшей модели логистической регрессии : 0.7643893420244171\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('tfidf', tf_idf), ('lr', LogisticRegression(random_state=rs, max_iter=1000, class_weight='balanced'))])\n",
    "\n",
    "param_grid = {\n",
    "    'lr__solver' : ['lbfgs', 'liblinear'],\n",
    "    'lr__C': [0.001, 0.01, 0.1, 1] + list(range(5, 16))\n",
    "}\n",
    "\n",
    "lr_grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=3, n_jobs=-1, scoring='f1')\n",
    "\n",
    "lr_grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(f\"Параметры лучшей модели логистической регрессии : {lr_grid_search.best_params_}\")\n",
    "print(f\"F1 для лучшей модели логистической регрессии : {lr_grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры лучшей модели случайного леса: {'rf__max_depth': 20, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n",
      "F1 для лучшей модели случайного леса: 0.40677642695030225\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('tfidf', tf_idf), ('rf', RandomForestClassifier(random_state=rs, class_weight='balanced'))])\n",
    "\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [10, 50, 100],\n",
    "    'rf__max_depth': [5, 10, 20],\n",
    "    'rf__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "    \n",
    "rf_grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=3, n_jobs=-1, scoring='f1')\n",
    "\n",
    "rf_grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(f\"Параметры лучшей модели случайного леса: {rf_grid_search.best_params_}\")\n",
    "print(f\"F1 для лучшей модели случайного леса: {rf_grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры лучшей модели LightGBM: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 20, 'lgbm__n_estimators': 100}\n",
      "F1 для лучшей модели LightGBM: 0.7377521246925239\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('tfidf', tf_idf), ('lgbm', LGBMClassifier(random_state=rs, verbose=-1, is_unbalance=True))])\n",
    "\n",
    "param_grid = {\n",
    "    'lgbm__n_estimators': [10, 50, 100],\n",
    "    'lgbm__max_depth': [5, 10, 20],\n",
    "    'lgbm__learning_rate': [0.03, 0.1]\n",
    "}\n",
    "\n",
    "lgbm_grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=3, n_jobs=-1, scoring='f1')\n",
    "\n",
    "lgbm_grid_search.fit(features_train, target_train)\n",
    "\n",
    "print(f\"Параметры лучшей модели LightGBM: {lgbm_grid_search.best_params_}\")\n",
    "print(f\"F1 для лучшей модели LightGBM: {lgbm_grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе была проведена подготовка данных и обучение трех различных моделей машинного обучения для классификации тональности текста на основе векторизации TF-IDF: Логистической регрессии, Случайного леса и LightGBM.  \n",
    "\n",
    "Результаты (метрика F1):\n",
    "- Логистическая регрессия : 0.764\n",
    "- Случайный лес : 0.407\n",
    "- LightGBM : 0.738\n",
    "\n",
    "Наилучший результат на кросс-валидации показала модель Логистической регрессии. На втором месте LightGBM. Модель Случайного леса показала худший результат. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем найденную на кросс-валидации лучшую модель для тестирования на тестовых данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = lr_grid_search.best_estimator_\n",
    "\n",
    "fitted_tf_idf = best_model.named_steps['tfidf']\n",
    "best_logreg_model = best_model.named_steps['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = fitted_tf_idf.transform(test['text_processed'])\n",
    "target_test = test['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.764933000227118"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(target_test, best_logreg_model.predict(tf_idf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показатель метрики F1 на тестовых данных равен 0.765, что удовлетворяет требованиям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель на адекватность путем сравнения показателя с показателем базовой (Dummy) модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model = DummyClassifier(strategy='most_frequent', random_state=rs)\n",
    "dummy_model.fit(fitted_tf_idf.transform(features_train), target_train)\n",
    "f1_score(target_test, dummy_model.predict(tf_idf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-метрика дамми-модели равна 0, так как модель никогда не предсказывает положительный класс. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы лучше понять, насколько адекватна наша модель, сравним показатели F1-macro, эта метрика показывает среднее по метрикам F1 для каждого класса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8678561105031695"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(target_test, best_logreg_model.predict(tf_idf_test), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47296885959688195"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(target_test, dummy_model.predict(tf_idf_test), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показатель среднего значения F1 для обученной модели равен 0.868, для дамми-модели 0.472, следовательно, проверка на адекватность пройдена. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе исследования были выполнены следующие шаги:\n",
    "\n",
    "1. Изучение данных: \n",
    "    - Дан датасет с 159292 записями, хранящий текст комментария и маркер \"токсичности\" комментария\n",
    "2. Предобработка данных. На данном этапе были проведены :\n",
    "    - Очистка текста от ненужных символов\n",
    "    - Приведение к нижнему регистру\n",
    "    - Удаление стоп-слов\n",
    "    - Лемматизация\n",
    "3. Обучение моделей\n",
    "    - Разделение данных на обучающую и тестовую выборку\n",
    "    - Была выполнена TF-IDF векторизация\n",
    "    - С помощью кросс-валидации были обучены три модели (Логистическая регрессия, Случайный лес, LightGBM) и определены лучшие значения гиперпараметров \n",
    "4. Оценка моделей \n",
    "    - Наилучший результат на кросс-валидации показала модель Логистической регрессии с метрикой F1 около 0.764, в то время как модель Случайного леса показала худший результат с метрикой F1 равной 0.407, и LightGBM показала результат сопоставимый с Логистической регрессией — 0.738.\n",
    "5. Тестирование \n",
    "    - Модель Логистической регресии с найденными лучшими значениниями гиперпараметров была проверена на адекватность путем сравнения с базовой моделью. Dummy-модель не смогла предсказать положительный класс (F1-метрика равна 0). Использование метрики F1-macro подтвердило адекватность обученной модели (0.868 против 0.472 у дамми-модели).\n",
    "    \n",
    "Таким образом, модель Логистической регрессии была обучена и протестирована на тестовой выборке, показатель F1 удовлетворяет требованиям (0.765 > 0.75). "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 365,
    "start_time": "2023-11-07T15:10:23.462Z"
   },
   {
    "duration": 104,
    "start_time": "2023-11-07T15:10:36.254Z"
   },
   {
    "duration": 2218,
    "start_time": "2023-11-07T15:10:55.343Z"
   },
   {
    "duration": 815,
    "start_time": "2023-11-07T15:11:05.548Z"
   },
   {
    "duration": 9,
    "start_time": "2023-11-07T15:11:11.165Z"
   },
   {
    "duration": 9,
    "start_time": "2023-11-07T15:16:57.852Z"
   },
   {
    "duration": 9,
    "start_time": "2023-11-07T15:17:07.349Z"
   },
   {
    "duration": 11,
    "start_time": "2023-11-07T15:17:24.988Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "315px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
